{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import torch\n",
    "import requests\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "from io import BytesIO\n",
    "from diffusers import StableDiffusionImg2ImgPipeline, ControlNetModel, StableDiffusionControlNetPipeline\n",
    "from diffusers.utils import load_image\n",
    "from controlnet_aux import OpenposeDetector, HEDdetector\n",
    "openpose = OpenposeDetector.from_pretrained(\"lllyasviel/ControlNet\")\n",
    "hed = HEDdetector.from_pretrained('lllyasviel/ControlNet')\n",
    "\n",
    "# cnmodel = \"lllyasviel/sd-controlnet-openpose\"\n",
    "# controlnet = ControlNetModel.from_pretrained(\n",
    "#     cnmodel,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     use_auth_token=TOKEN,\n",
    "# )\n",
    "#     ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\", torch_dtype=torch.float16),\n",
    "#     ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-hed\", torch_dtype=torch.float16)\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-openpose\", torch_dtype=torch.float16)\n",
    "\n",
    "device = \"cuda\"\n",
    "i2ipl = \"Lykon/DreamShaper\"\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    i2ipl,\n",
    "    controlnet=controlnet,\n",
    "    safety_checker=None,\n",
    "    torch_dtype=torch.float16,\n",
    "    # use_auth_token=TOKEN,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_path = \"pic/pose12.jpg\"\n",
    "pose = Image.open(pose_path).convert(\"RGB\")\n",
    "openpose_image = openpose(pose)\n",
    "# Define the cropping area (left, upper, right, lower)\n",
    "crop_area = (100,200,400,700)\n",
    "pose = openpose_image.crop(crop_area)\n",
    "# width, height = pose.size\n",
    "# scale = 4\n",
    "# new_w, new_h = width*scale, height*scale\n",
    "# pose = pose.resize((new_w, new_h), Image.ANTIALIAS)\n",
    "pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Smiling Spartan warrior, bald, beard to his chest, muscle, sitting on the throne, upper-naked, straightforward, tilting his head, below vermillion sky, Roman shrine, highly detailed, 4k\"\n",
    "negative_prompt = \"closeup, (deformed iris, deformed pupils, cgi, render, sketch, cartoon, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck\"\n",
    "generator = torch.Generator(device=device).manual_seed(1024)\n",
    "image = pipe(prompt=prompt, negative_prompt=negative_prompt, image=pose, guidance_scale=8, num_inference_steps=100, generator=generator).images[0]\n",
    "now = datetime.now()\n",
    "formatted_time = now.strftime(\"%Y%m%d%H%M%S\")\n",
    "image.save(f'pic/{formatted_time}.png')\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
